{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e568f0d6",
   "metadata": {},
   "source": [
    "# vessel-cable-anomaly-hunter\n",
    "DTU Deep Learning project 29, group 80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425814a0",
   "metadata": {},
   "source": [
    "## Required Libraries Installation\n",
    "Run this in your terminal before executing this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6f609e",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccd44da",
   "metadata": {},
   "source": [
    "## 1) Data Download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c347b624",
   "metadata": {},
   "source": [
    "#### File imports for the data download and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c203ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import src.data.ais_downloader as ais_downloader\n",
    "import src.data.ais_filtering as ais_filtering\n",
    "import src.data.ais_reader as ais_reader\n",
    "import src.data.ais_to_parquet as ais_to_parquet\n",
    "\n",
    "import src.data.ais_reader as ais_reader\n",
    "import src.pre_proc.ais_query as ais_query \n",
    "import src.utils.ais_maps as ais_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3813a859",
   "metadata": {},
   "source": [
    "#### Library imports for the data download and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc178db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65675b5f",
   "metadata": {},
   "source": [
    "#### Set data preferences and configuration inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c341eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE_MODE = config.VERBOSE_MODE                          # Whether to print verbose output\n",
    "\n",
    "START_DATE = config.START_DATE                              # Start date for data downloading\n",
    "END_DATE   = config.END_DATE                                # End date for data downloading\n",
    "\n",
    "AIS_DATA_NAME = config.AIS_DATA_FOLDER                      # Name of the folder to store AIS data\n",
    "DELETE_DOWNLOADED_CSV = config.DELETE_DOWNLOADED_CSV        # Whether to delete raw downloaded CSV files after processing\n",
    "\n",
    "VESSEL_AIS_CLASS = config.VESSEL_AIS_CLASS                  # AIS classes of vessels to include\n",
    "\n",
    "REMOVE_ZERO_SOG_VESSELS = config.REMOVE_ZERO_SOG_VESSELS    # Whether to remove vessels with zero Speed Over Ground\n",
    "SOG_IN_MS = config.SOG_IN_MS                                # If True, SOG is in meters/second; if False, SOG is in knots\n",
    "SOG_MIN_KNOTS = config.SOG_MIN_KNOTS                        # Minimum SOG in knots\n",
    "SOG_MAX_KNOTS = config.SOG_MAX_KNOTS                        # Maximum SOG in knots\n",
    "\n",
    "BBOX = config.BBOX                                          # Bounding Box to prefilter AIS data\n",
    "POLYGON_COORDINATES = config.POLYGON_COORDINATES            # Polygon coordinates for filter Area of Interest\n",
    "COLUMNS_TO_DROP = config.COLUMNS_TO_DROP                    # Columns to drop from AIS data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9d8db5",
   "metadata": {},
   "source": [
    "#### Create Directories and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2a99188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create paths ---\n",
    "folder_path = Path(AIS_DATA_NAME)\n",
    "folder_path.mkdir(parents=True, exist_ok=True)\n",
    "csv_folder_path = folder_path / \"csv\"\n",
    "csv_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "parquet_folder_path = folder_path / \"parquet\"\n",
    "parquet_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "file_port_locations = folder_path / \"port_locodes.csv\" # Path to port locations file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98948aa7",
   "metadata": {},
   "source": [
    "#### Main Script\n",
    "1) Download one single .csv AIS data file from http://aisdata.ais.dk (link to data column description http://aisdata.ais.dk/!_README_information_CSV_files.txt);\n",
    "2) For a given AOI in Denmark with known cable positions, filter AIS messages by cleansing unrealistic/unphysical messages or duplicates and removes error-prone messages within port areas;\n",
    "3) Segmentation of vessel tracks per MMSI and date;\n",
    "4) Parquet Conversion;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24af940c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 0/30 [00:00<?, ?file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing date: 2025-08-01\n",
      "Skipping 2025-08-01 download: already present in ais-data/csv folder\n",
      "Read AIS data: 1,128,873 rows within bbox, 511 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,128,873 rows, 511 vessels\n",
      " [filter_ais_df] Type filtering: 1,093,101 rows (removed 35,772) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,093,079 rows, 508 vessels\n",
      " [filter_ais_df] Duplicate removal: 638,467 rows, 508 vessels\n",
      " [filter_ais_df] Polygon filtering: 337,847 rows (removed 300,620), 378 vessels\n",
      " [filter_ais_df] Port-area removal: removed 160,778 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 175,598 rows (removed 1,471) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 173,215 rows (removed 2,381) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 173,215 rows, 327 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 327 (MMSI, Date) combinations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   3%|▎         | 1/30 [00:08<04:16,  8.86s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n",
      "\n",
      "Processing date: 2025-08-02\n",
      "Skipping 2025-08-02 download: already present in ais-data/csv folder\n",
      "Read AIS data: 1,161,214 rows within bbox, 452 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,161,214 rows, 452 vessels\n",
      " [filter_ais_df] Type filtering: 1,120,127 rows (removed 41,087) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,114,486 rows, 447 vessels\n",
      " [filter_ais_df] Duplicate removal: 616,865 rows, 447 vessels\n",
      " [filter_ais_df] Polygon filtering: 314,494 rows (removed 302,371), 342 vessels\n",
      " [filter_ais_df] Port-area removal: removed 168,854 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 145,303 rows (removed 337) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 144,010 rows (removed 1,291) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 144,010 rows, 290 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 290 (MMSI, Date) combinations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   7%|▋         | 2/30 [00:18<04:23,  9.43s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n",
      "\n",
      "Processing date: 2025-08-03\n",
      "Skipping 2025-08-03 download: already present in ais-data/csv folder\n",
      "Read AIS data: 1,079,891 rows within bbox, 399 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,079,891 rows, 399 vessels\n",
      " [filter_ais_df] Type filtering: 1,043,284 rows (removed 36,607) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,043,284 rows, 398 vessels\n",
      " [filter_ais_df] Duplicate removal: 599,515 rows, 398 vessels\n",
      " [filter_ais_df] Polygon filtering: 319,478 rows (removed 280,037), 288 vessels\n",
      " [filter_ais_df] Port-area removal: removed 165,183 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 153,909 rows (removed 386) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 152,641 rows (removed 1,266) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 152,641 rows, 248 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 248 (MMSI, Date) combinations.\n",
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  10%|█         | 3/30 [00:27<04:08,  9.19s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing date: 2025-08-04\n",
      "Skipping 2025-08-04 download: already present in ais-data/csv folder\n",
      "Read AIS data: 1,161,332 rows within bbox, 380 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,161,332 rows, 380 vessels\n",
      " [filter_ais_df] Type filtering: 1,125,031 rows (removed 36,301) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,125,031 rows, 379 vessels\n",
      " [filter_ais_df] Duplicate removal: 637,785 rows, 379 vessels\n",
      " [filter_ais_df] Polygon filtering: 321,848 rows (removed 315,937), 272 vessels\n",
      " [filter_ais_df] Port-area removal: removed 156,758 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 164,980 rows (removed 110) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 162,923 rows (removed 2,057) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 162,923 rows, 232 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 232 (MMSI, Date) combinations.\n",
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  13%|█▎        | 4/30 [00:35<03:47,  8.74s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing date: 2025-08-05\n",
      "Skipping 2025-08-05 download: already present in ais-data/csv folder\n",
      "Read AIS data: 1,157,746 rows within bbox, 268 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,157,746 rows, 268 vessels\n",
      " [filter_ais_df] Type filtering: 1,119,953 rows (removed 37,793) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,116,828 rows, 264 vessels\n",
      " [filter_ais_df] Duplicate removal: 613,845 rows, 264 vessels\n",
      " [filter_ais_df] Polygon filtering: 301,015 rows (removed 312,830), 175 vessels\n",
      " [filter_ais_df] Port-area removal: removed 171,761 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 129,228 rows (removed 26) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 127,182 rows (removed 2,046) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 127,182 rows, 115 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 115 (MMSI, Date) combinations.\n",
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  17%|█▋        | 5/30 [00:45<03:49,  9.17s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing date: 2025-08-06\n",
      "Skipping 2025-08-06 download: already present in ais-data/csv folder\n",
      "Read AIS data: 1,145,520 rows within bbox, 261 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,145,520 rows, 261 vessels\n",
      " [filter_ais_df] Type filtering: 1,108,897 rows (removed 36,623) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,108,897 rows, 260 vessels\n",
      " [filter_ais_df] Duplicate removal: 622,309 rows, 260 vessels\n",
      " [filter_ais_df] Polygon filtering: 300,756 rows (removed 321,553), 169 vessels\n",
      " [filter_ais_df] Port-area removal: removed 163,859 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 136,873 rows (removed 24) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 134,698 rows (removed 2,175) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 134,698 rows, 123 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 123 (MMSI, Date) combinations.\n",
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  20%|██        | 6/30 [00:53<03:29,  8.72s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing date: 2025-08-07\n",
      "Skipping 2025-08-07 download: already present in ais-data/csv folder\n",
      "Read AIS data: 1,202,886 rows within bbox, 385 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,202,886 rows, 385 vessels\n",
      " [filter_ais_df] Type filtering: 1,166,600 rows (removed 36,286) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,162,713 rows, 382 vessels\n",
      " [filter_ais_df] Duplicate removal: 642,517 rows, 382 vessels\n",
      " [filter_ais_df] Polygon filtering: 301,062 rows (removed 341,455), 277 vessels\n",
      " [filter_ais_df] Port-area removal: removed 133,073 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 167,842 rows (removed 147) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 166,354 rows (removed 1,488) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 166,354 rows, 247 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 247 (MMSI, Date) combinations.\n",
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  23%|██▎       | 7/30 [01:02<03:19,  8.68s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing date: 2025-08-08\n",
      "Skipping 2025-08-08 download: already present in ais-data/csv folder\n",
      "Read AIS data: 1,160,724 rows within bbox, 399 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,160,724 rows, 399 vessels\n",
      " [filter_ais_df] Type filtering: 1,124,268 rows (removed 36,456) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,124,255 rows, 397 vessels\n",
      " [filter_ais_df] Duplicate removal: 618,010 rows, 397 vessels\n",
      " [filter_ais_df] Polygon filtering: 270,458 rows (removed 347,552), 285 vessels\n",
      " [filter_ais_df] Port-area removal: removed 115,708 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 154,292 rows (removed 458) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 151,933 rows (removed 2,359) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 151,933 rows, 262 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 262 (MMSI, Date) combinations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  27%|██▋       | 8/30 [01:11<03:13,  8.81s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n",
      "\n",
      "Processing date: 2025-08-09\n",
      "Skipping 2025-08-09 download: already present in ais-data/csv folder\n",
      "Read AIS data: 1,206,051 rows within bbox, 424 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,206,051 rows, 424 vessels\n",
      " [filter_ais_df] Type filtering: 1,168,258 rows (removed 37,793) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,168,258 rows, 423 vessels\n",
      " [filter_ais_df] Duplicate removal: 649,751 rows, 423 vessels\n",
      " [filter_ais_df] Polygon filtering: 292,802 rows (removed 356,949), 308 vessels\n",
      " [filter_ais_df] Port-area removal: removed 132,829 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 159,617 rows (removed 356) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 158,925 rows (removed 692) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 158,925 rows, 271 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 271 (MMSI, Date) combinations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  30%|███       | 9/30 [01:22<03:23,  9.71s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n",
      "\n",
      "Processing date: 2025-08-10\n",
      "Skipping 2025-08-10 download: already present in ais-data/csv folder\n",
      "Read AIS data: 1,032,887 rows within bbox, 304 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,032,887 rows, 304 vessels\n",
      " [filter_ais_df] Type filtering: 996,909 rows (removed 35,978) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 996,909 rows, 303 vessels\n",
      " [filter_ais_df] Duplicate removal: 577,793 rows, 303 vessels\n",
      " [filter_ais_df] Polygon filtering: 253,367 rows (removed 324,426), 202 vessels\n",
      " [filter_ais_df] Port-area removal: removed 135,402 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 117,942 rows (removed 23) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 116,931 rows (removed 1,011) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 116,931 rows, 160 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 160 (MMSI, Date) combinations.\n",
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  33%|███▎      | 10/30 [01:30<03:03,  9.19s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing date: 2025-08-11\n",
      "Skipping 2025-08-11 download: already present in ais-data/csv folder\n",
      "Read AIS data: 1,156,494 rows within bbox, 368 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,156,494 rows, 368 vessels\n",
      " [filter_ais_df] Type filtering: 1,120,818 rows (removed 35,676) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,120,789 rows, 365 vessels\n",
      " [filter_ais_df] Duplicate removal: 658,127 rows, 365 vessels\n",
      " [filter_ais_df] Polygon filtering: 332,555 rows (removed 325,572), 275 vessels\n",
      " [filter_ais_df] Port-area removal: removed 128,044 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 204,484 rows (removed 27) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 201,774 rows (removed 2,710) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 201,774 rows, 247 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 247 (MMSI, Date) combinations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  37%|███▋      | 11/30 [01:39<02:51,  9.02s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n",
      "\n",
      "Processing date: 2025-08-12\n",
      "Skipping 2025-08-12 download: already present in ais-data/csv folder\n",
      "Read AIS data: 1,266,622 rows within bbox, 410 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,266,622 rows, 410 vessels\n",
      " [filter_ais_df] Type filtering: 1,229,954 rows (removed 36,668) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,229,743 rows, 407 vessels\n",
      " [filter_ais_df] Duplicate removal: 684,142 rows, 407 vessels\n",
      " [filter_ais_df] Polygon filtering: 369,055 rows (removed 315,087), 295 vessels\n",
      " [filter_ais_df] Port-area removal: removed 115,656 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 252,095 rows (removed 1,304) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 250,511 rows (removed 1,581) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 250,511 rows, 276 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 276 (MMSI, Date) combinations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  40%|████      | 12/30 [01:51<02:56,  9.81s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n",
      "\n",
      "Processing date: 2025-08-13\n",
      "Skipping 2025-08-13 download: already present in ais-data/csv folder\n",
      "Read AIS data: 1,795,771 rows within bbox, 469 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,795,771 rows, 469 vessels\n",
      " [filter_ais_df] Type filtering: 1,748,562 rows (removed 47,209) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,748,279 rows, 464 vessels\n",
      " [filter_ais_df] Duplicate removal: 741,922 rows, 464 vessels\n",
      " [filter_ais_df] Polygon filtering: 385,020 rows (removed 356,902), 324 vessels\n",
      " [filter_ais_df] Port-area removal: removed 123,372 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 257,045 rows (removed 4,603) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 250,534 rows (removed 6,492) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 250,534 rows, 293 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 293 (MMSI, Date) combinations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  43%|████▎     | 13/30 [02:05<03:08, 11.10s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n",
      "\n",
      "Processing date: 2025-08-14\n",
      "Skipping 2025-08-14 download: already present in ais-data/csv folder\n",
      "Read AIS data: 1,735,081 rows within bbox, 453 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,735,081 rows, 453 vessels\n",
      " [filter_ais_df] Type filtering: 1,685,982 rows (removed 49,099) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,681,923 rows, 450 vessels\n",
      " [filter_ais_df] Duplicate removal: 686,298 rows, 450 vessels\n",
      " [filter_ais_df] Polygon filtering: 336,864 rows (removed 349,434), 319 vessels\n",
      " [filter_ais_df] Port-area removal: removed 120,164 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 212,437 rows (removed 4,263) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 209,294 rows (removed 3,142) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 209,294 rows, 276 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 276 (MMSI, Date) combinations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  47%|████▋     | 14/30 [02:20<03:19, 12.45s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n",
      "\n",
      "Processing date: 2025-08-15\n",
      "Starting download and extraction for 2025-08-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 2025-08-15 zip file: 100%|██████████| 743M/743M [00:21<00:00, 36.1MB/s]\n",
      "Unzipping into ais-data/csv folder : 100%|██████████| 1/1 [00:19<00:00, 19.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted downloaded zip file for 2025-08-15\n",
      "Completed download and extraction for 2025-08-15\n",
      "Read AIS data: 1,174,842 rows within bbox, 448 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,174,842 rows, 448 vessels\n",
      " [filter_ais_df] Type filtering: 1,136,029 rows (removed 38,813) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,135,364 rows, 444 vessels\n",
      " [filter_ais_df] Duplicate removal: 629,432 rows, 444 vessels\n",
      " [filter_ais_df] Polygon filtering: 309,560 rows (removed 319,872), 332 vessels\n",
      " [filter_ais_df] Port-area removal: removed 127,775 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 180,449 rows (removed 1,336) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 178,299 rows (removed 2,130) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 178,299 rows, 292 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 292 (MMSI, Date) combinations.\n",
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  50%|█████     | 15/30 [03:12<06:03, 24.22s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing date: 2025-08-16\n",
      "Starting download and extraction for 2025-08-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 2025-08-16 zip file: 100%|██████████| 660M/660M [00:27<00:00, 25.1MB/s]\n",
      "Unzipping into ais-data/csv folder : 100%|██████████| 1/1 [00:17<00:00, 17.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted downloaded zip file for 2025-08-16\n",
      "Completed download and extraction for 2025-08-16\n",
      "Read AIS data: 1,255,838 rows within bbox, 416 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,255,838 rows, 416 vessels\n",
      " [filter_ais_df] Type filtering: 1,217,153 rows (removed 38,685) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,214,773 rows, 412 vessels\n",
      " [filter_ais_df] Duplicate removal: 610,454 rows, 412 vessels\n",
      " [filter_ais_df] Polygon filtering: 312,456 rows (removed 297,998), 302 vessels\n",
      " [filter_ais_df] Port-area removal: removed 169,285 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 141,891 rows (removed 1,280) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 139,551 rows (removed 2,339) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 139,551 rows, 246 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 246 (MMSI, Date) combinations.\n",
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  53%|█████▎    | 16/30 [04:06<07:44, 33.21s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing date: 2025-08-17\n",
      "Starting download and extraction for 2025-08-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 2025-08-17 zip file: 100%|██████████| 719M/719M [00:19<00:00, 37.7MB/s]\n",
      "Unzipping into ais-data/csv folder : 100%|██████████| 1/1 [00:19<00:00, 19.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted downloaded zip file for 2025-08-17\n",
      "Completed download and extraction for 2025-08-17\n",
      "Read AIS data: 1,401,996 rows within bbox, 420 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,401,996 rows, 420 vessels\n",
      " [filter_ais_df] Type filtering: 1,359,332 rows (removed 42,664) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,358,756 rows, 416 vessels\n",
      " [filter_ais_df] Duplicate removal: 605,191 rows, 416 vessels\n",
      " [filter_ais_df] Polygon filtering: 319,959 rows (removed 285,232), 288 vessels\n",
      " [filter_ais_df] Port-area removal: removed 153,953 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 164,187 rows (removed 1,819) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 161,059 rows (removed 3,128) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 161,059 rows, 240 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 240 (MMSI, Date) combinations.\n",
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  57%|█████▋    | 17/30 [04:57<08:20, 38.49s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing date: 2025-08-18\n",
      "Starting download and extraction for 2025-08-18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 2025-08-18 zip file: 100%|██████████| 850M/850M [00:29<00:00, 30.2MB/s]\n",
      "Unzipping into ais-data/csv folder : 100%|██████████| 1/1 [00:24<00:00, 24.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted downloaded zip file for 2025-08-18\n",
      "Completed download and extraction for 2025-08-18\n",
      "Read AIS data: 1,835,907 rows within bbox, 472 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,835,907 rows, 472 vessels\n",
      " [filter_ais_df] Type filtering: 1,788,245 rows (removed 47,662) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,787,688 rows, 469 vessels\n",
      " [filter_ais_df] Duplicate removal: 637,476 rows, 469 vessels\n",
      " [filter_ais_df] Polygon filtering: 356,262 rows (removed 281,214), 339 vessels\n",
      " [filter_ais_df] Port-area removal: removed 127,245 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 224,904 rows (removed 4,113) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 220,673 rows (removed 4,228) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 220,673 rows, 305 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 305 (MMSI, Date) combinations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  60%|██████    | 18/30 [06:06<09:35, 47.94s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n",
      "\n",
      "Processing date: 2025-08-19\n",
      "Starting download and extraction for 2025-08-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 2025-08-19 zip file: 100%|██████████| 690M/690M [00:19<00:00, 36.3MB/s]\n",
      "Unzipping into ais-data/csv folder : 100%|██████████| 1/1 [00:19<00:00, 19.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted downloaded zip file for 2025-08-19\n",
      "Completed download and extraction for 2025-08-19\n",
      "Read AIS data: 1,116,204 rows within bbox, 343 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,116,204 rows, 343 vessels\n",
      " [filter_ais_df] Type filtering: 1,078,257 rows (removed 37,947) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,078,165 rows, 340 vessels\n",
      " [filter_ais_df] Duplicate removal: 556,725 rows, 340 vessels\n",
      " [filter_ais_df] Polygon filtering: 305,401 rows (removed 251,324), 235 vessels\n",
      " [filter_ais_df] Port-area removal: removed 129,632 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 173,790 rows (removed 1,979) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 170,265 rows (removed 3,518) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 170,265 rows, 195 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 195 (MMSI, Date) combinations.\n",
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  63%|██████▎   | 19/30 [06:56<08:52, 48.40s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing date: 2025-08-20\n",
      "Starting download and extraction for 2025-08-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 2025-08-20 zip file: 100%|██████████| 642M/642M [00:18<00:00, 36.7MB/s]\n",
      "Unzipping into ais-data/csv folder : 100%|██████████| 1/1 [00:16<00:00, 16.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted downloaded zip file for 2025-08-20\n",
      "Completed download and extraction for 2025-08-20\n",
      "Read AIS data: 1,015,814 rows within bbox, 360 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,015,814 rows, 360 vessels\n",
      " [filter_ais_df] Type filtering: 980,694 rows (removed 35,120) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 978,608 rows, 356 vessels\n",
      " [filter_ais_df] Duplicate removal: 587,058 rows, 356 vessels\n",
      " [filter_ais_df] Polygon filtering: 320,782 rows (removed 266,276), 257 vessels\n",
      " [filter_ais_df] Port-area removal: removed 129,834 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 186,653 rows (removed 4,295) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 184,839 rows (removed 1,789) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 184,839 rows, 227 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 227 (MMSI, Date) combinations.\n",
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  67%|██████▋   | 20/30 [07:41<07:54, 47.47s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing date: 2025-08-21\n",
      "Starting download and extraction for 2025-08-21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 2025-08-21 zip file: 100%|██████████| 615M/615M [00:17<00:00, 37.8MB/s]\n",
      "Unzipping into ais-data/csv folder : 100%|██████████| 1/1 [00:16<00:00, 16.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted downloaded zip file for 2025-08-21\n",
      "Completed download and extraction for 2025-08-21\n",
      "Read AIS data: 1,032,805 rows within bbox, 317 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,032,805 rows, 317 vessels\n",
      " [filter_ais_df] Type filtering: 998,010 rows (removed 34,795) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 993,072 rows, 313 vessels\n",
      " [filter_ais_df] Duplicate removal: 576,822 rows, 313 vessels\n",
      " [filter_ais_df] Polygon filtering: 310,064 rows (removed 266,758), 227 vessels\n",
      " [filter_ais_df] Port-area removal: removed 107,074 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 185,525 rows (removed 17,465) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 183,897 rows (removed 1,579) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 183,897 rows, 193 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 193 (MMSI, Date) combinations.\n",
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  70%|███████   | 21/30 [08:24<06:54, 46.03s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing date: 2025-08-22\n",
      "Starting download and extraction for 2025-08-22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 2025-08-22 zip file: 100%|██████████| 599M/599M [00:17<00:00, 34.9MB/s]\n",
      "Unzipping into ais-data/csv folder : 100%|██████████| 1/1 [00:15<00:00, 15.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted downloaded zip file for 2025-08-22\n",
      "Completed download and extraction for 2025-08-22\n",
      "Read AIS data: 1,067,486 rows within bbox, 322 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,067,486 rows, 322 vessels\n",
      " [filter_ais_df] Type filtering: 1,030,816 rows (removed 36,670) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,030,463 rows, 317 vessels\n",
      " [filter_ais_df] Duplicate removal: 567,896 rows, 317 vessels\n",
      " [filter_ais_df] Polygon filtering: 259,900 rows (removed 307,996), 225 vessels\n",
      " [filter_ais_df] Port-area removal: removed 127,301 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 132,469 rows (removed 130) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 132,046 rows (removed 423) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 132,046 rows, 196 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 196 (MMSI, Date) combinations.\n",
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  73%|███████▎  | 22/30 [09:06<05:59, 44.89s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing date: 2025-08-23\n",
      "Starting download and extraction for 2025-08-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 2025-08-23 zip file: 100%|██████████| 626M/626M [00:18<00:00, 36.3MB/s]\n",
      "Unzipping into ais-data/csv folder : 100%|██████████| 1/1 [00:16<00:00, 16.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted downloaded zip file for 2025-08-23\n",
      "Completed download and extraction for 2025-08-23\n",
      "Read AIS data: 929,511 rows within bbox, 288 unique vessels\n",
      " [filter_ais_df] Before filtering: 929,511 rows, 288 vessels\n",
      " [filter_ais_df] Type filtering: 893,704 rows (removed 35,807) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 889,249 rows, 284 vessels\n",
      " [filter_ais_df] Duplicate removal: 499,248 rows, 284 vessels\n",
      " [filter_ais_df] Polygon filtering: 226,615 rows (removed 272,633), 182 vessels\n",
      " [filter_ais_df] Port-area removal: removed 136,806 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 89,305 rows (removed 504) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 89,285 rows (removed 15) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 89,285 rows, 144 unique vessels (SOG in m/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  77%|███████▋  | 23/30 [09:49<05:09, 44.16s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [save_by_mmsi] Removed existing partitions for 144 (MMSI, Date) combinations.\n",
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n",
      "\n",
      "Processing date: 2025-08-24\n",
      "Starting download and extraction for 2025-08-24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 2025-08-24 zip file: 100%|██████████| 637M/637M [00:24<00:00, 27.2MB/s]\n",
      "Unzipping into ais-data/csv folder : 100%|██████████| 1/1 [00:16<00:00, 16.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted downloaded zip file for 2025-08-24\n",
      "Completed download and extraction for 2025-08-24\n",
      "Read AIS data: 1,237,843 rows within bbox, 379 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,237,843 rows, 379 vessels\n",
      " [filter_ais_df] Type filtering: 1,199,187 rows (removed 38,656) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,198,723 rows, 377 vessels\n",
      " [filter_ais_df] Duplicate removal: 562,533 rows, 377 vessels\n",
      " [filter_ais_df] Polygon filtering: 262,149 rows (removed 300,384), 262 vessels\n",
      " [filter_ais_df] Port-area removal: removed 102,306 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 156,693 rows (removed 3,150) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 152,349 rows (removed 4,324) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 152,349 rows, 235 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 235 (MMSI, Date) combinations.\n",
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  80%|████████  | 24/30 [10:39<04:36, 46.15s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing date: 2025-08-25\n",
      "Starting download and extraction for 2025-08-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 2025-08-25 zip file: 100%|██████████| 634M/634M [00:22<00:00, 29.5MB/s]\n",
      "Unzipping into ais-data/csv folder : 100%|██████████| 1/1 [00:16<00:00, 16.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted downloaded zip file for 2025-08-25\n",
      "Completed download and extraction for 2025-08-25\n",
      "Read AIS data: 1,098,224 rows within bbox, 390 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,098,224 rows, 390 vessels\n",
      " [filter_ais_df] Type filtering: 1,063,350 rows (removed 34,874) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,063,263 rows, 387 vessels\n",
      " [filter_ais_df] Duplicate removal: 605,356 rows, 387 vessels\n",
      " [filter_ais_df] Polygon filtering: 308,699 rows (removed 296,657), 280 vessels\n",
      " [filter_ais_df] Port-area removal: removed 68,865 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 235,327 rows (removed 4,507) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 229,652 rows (removed 5,663) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 229,652 rows, 259 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 259 (MMSI, Date) combinations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  83%|████████▎ | 25/30 [11:28<03:54, 46.96s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n",
      "\n",
      "Processing date: 2025-08-26\n",
      "Starting download and extraction for 2025-08-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 2025-08-26 zip file: 100%|██████████| 726M/726M [00:20<00:00, 38.0MB/s]\n",
      "Unzipping into ais-data/csv folder : 100%|██████████| 1/1 [00:19<00:00, 19.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted downloaded zip file for 2025-08-26\n",
      "Completed download and extraction for 2025-08-26\n",
      "Read AIS data: 1,128,401 rows within bbox, 390 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,128,401 rows, 390 vessels\n",
      " [filter_ais_df] Type filtering: 1,090,256 rows (removed 38,145) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,090,197 rows, 387 vessels\n",
      " [filter_ais_df] Duplicate removal: 621,389 rows, 387 vessels\n",
      " [filter_ais_df] Polygon filtering: 323,734 rows (removed 297,655), 282 vessels\n",
      " [filter_ais_df] Port-area removal: removed 77,024 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 244,339 rows (removed 2,371) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 239,853 rows (removed 4,463) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 239,853 rows, 260 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 260 (MMSI, Date) combinations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  87%|████████▋ | 26/30 [12:18<03:11, 47.87s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n",
      "\n",
      "Processing date: 2025-08-27\n",
      "Starting download and extraction for 2025-08-27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 2025-08-27 zip file: 100%|██████████| 722M/722M [00:25<00:00, 29.4MB/s]\n",
      "Unzipping into ais-data/csv folder : 100%|██████████| 1/1 [00:19<00:00, 19.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted downloaded zip file for 2025-08-27\n",
      "Completed download and extraction for 2025-08-27\n",
      "Read AIS data: 1,125,714 rows within bbox, 323 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,125,714 rows, 323 vessels\n",
      " [filter_ais_df] Type filtering: 1,085,063 rows (removed 40,651) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,083,741 rows, 320 vessels\n",
      " [filter_ais_df] Duplicate removal: 568,815 rows, 320 vessels\n",
      " [filter_ais_df] Polygon filtering: 276,814 rows (removed 292,001), 213 vessels\n",
      " [filter_ais_df] Port-area removal: removed 88,540 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 188,100 rows (removed 174) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 184,610 rows (removed 3,486) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 184,610 rows, 187 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 187 (MMSI, Date) combinations.\n",
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  90%|█████████ | 27/30 [13:15<02:31, 50.38s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing date: 2025-08-28\n",
      "Starting download and extraction for 2025-08-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 2025-08-28 zip file: 100%|██████████| 718M/718M [00:20<00:00, 36.0MB/s]\n",
      "Unzipping into ais-data/csv folder : 100%|██████████| 1/1 [00:19<00:00, 19.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted downloaded zip file for 2025-08-28\n",
      "Completed download and extraction for 2025-08-28\n",
      "Read AIS data: 1,520,546 rows within bbox, 369 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,520,546 rows, 369 vessels\n",
      " [filter_ais_df] Type filtering: 1,469,075 rows (removed 51,471) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,467,773 rows, 365 vessels\n",
      " [filter_ais_df] Duplicate removal: 590,590 rows, 365 vessels\n",
      " [filter_ais_df] Polygon filtering: 266,691 rows (removed 323,899), 250 vessels\n",
      " [filter_ais_df] Port-area removal: removed 82,210 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 182,000 rows (removed 2,481) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 178,136 rows (removed 3,864) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 178,136 rows, 224 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 224 (MMSI, Date) combinations.\n",
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  93%|█████████▎| 28/30 [14:09<01:43, 51.54s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing date: 2025-08-29\n",
      "Starting download and extraction for 2025-08-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 2025-08-29 zip file: 100%|██████████| 680M/680M [00:19<00:00, 36.5MB/s]\n",
      "Unzipping into ais-data/csv folder : 100%|██████████| 1/1 [00:18<00:00, 18.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted downloaded zip file for 2025-08-29\n",
      "Completed download and extraction for 2025-08-29\n",
      "Read AIS data: 1,146,177 rows within bbox, 336 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,146,177 rows, 336 vessels\n",
      " [filter_ais_df] Type filtering: 1,105,492 rows (removed 40,685) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,104,921 rows, 329 vessels\n",
      " [filter_ais_df] Duplicate removal: 569,091 rows, 329 vessels\n",
      " [filter_ais_df] Polygon filtering: 245,059 rows (removed 324,032), 224 vessels\n",
      " [filter_ais_df] Port-area removal: removed 109,816 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 135,195 rows (removed 48) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 133,338 rows (removed 1,857) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 133,338 rows, 199 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 199 (MMSI, Date) combinations.\n",
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  97%|█████████▋| 29/30 [14:56<00:50, 50.38s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing date: 2025-08-30\n",
      "Starting download and extraction for 2025-08-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 2025-08-30 zip file: 100%|██████████| 675M/675M [00:17<00:00, 40.5MB/s]\n",
      "Unzipping into ais-data/csv folder : 100%|██████████| 1/1 [00:18<00:00, 18.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted downloaded zip file for 2025-08-30\n",
      "Completed download and extraction for 2025-08-30\n",
      "Read AIS data: 1,220,338 rows within bbox, 346 unique vessels\n",
      " [filter_ais_df] Before filtering: 1,220,338 rows, 346 vessels\n",
      " [filter_ais_df] Type filtering: 1,175,090 rows (removed 45,248) using ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering: 1,172,421 rows, 343 vessels\n",
      " [filter_ais_df] Duplicate removal: 555,626 rows, 343 vessels\n",
      " [filter_ais_df] Polygon filtering: 250,792 rows (removed 304,834), 228 vessels\n",
      " [filter_ais_df] Port-area removal: removed 131,407 rows in 3 overlapping ports\n",
      " [filter_ais_df] COG sanity: 118,470 rows (removed 915) with range [0, 360] deg\n",
      " [filter_ais_df] SOG sanity: 116,550 rows (removed 1,920) with range [0.5, 35.0] knots\n",
      " [filter_ais_df] Final: 116,550 rows, 195 unique vessels (SOG in m/s)\n",
      " [save_by_mmsi] Removed existing partitions for 195 (MMSI, Date) combinations.\n",
      " [save_by_mmsi] Parquet dataset written/appended at: /dtu/blackhole/0e/213550/dark-vessel-hunter/ais-data/parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 30/30 [15:42<00:00, 31.41s/file]\n"
     ]
    }
   ],
   "source": [
    "# --- If you want to download all csv files before, uncomment the line below ---\n",
    "# ais_downloader.download_multiple_ais_data(START_DATE, END_DATE, folder_path)\n",
    "\n",
    "# --- Build the schedule of download string dates ---\n",
    "dates = ais_downloader.get_work_dates(START_DATE, END_DATE, csv_folder_path, filter=False)\n",
    "\n",
    "# --- Iterate with tqdm and download, unzip and delete ---\n",
    "for day in tqdm(dates, desc=f\"Processing data\", unit=\"file\" ):\n",
    "    tag = f\"{day:%Y-%m}\" if day < date.fromisoformat(\"2024-03-01\") else f\"{day:%Y-%m-%d}\"\n",
    "    print(f\"\\nProcessing date: {tag}\")\n",
    "\n",
    "    # --- Download one day ---\n",
    "    csv_path = ais_downloader.download_one_ais_data(day, csv_folder_path)\n",
    "    \n",
    "    # --- Load CSV into DataFrame ---\n",
    "    df_raw = ais_reader.read_single_ais_df(csv_path, BBOX, columns_to_drop=COLUMNS_TO_DROP, verbose=VERBOSE_MODE)\n",
    "    # --- Optionally delete the downloaded CSV file ---\n",
    "    if DELETE_DOWNLOADED_CSV: csv_path.unlink(missing_ok=True)\n",
    "    \n",
    "    # --- Filter and split ---\n",
    "    # Filter AIS data, keeping Class A and Class B by default,\n",
    "    df_filtered = ais_filtering.filter_ais_df(\n",
    "        df_raw,                                               # raw AIS DataFrame\n",
    "        polygon_coords=POLYGON_COORDINATES,                   # polygon coordinates for precise AOI filtering\n",
    "        allowed_mobile_types=VESSEL_AIS_CLASS,                # vessel AIS class filter\n",
    "        apply_polygon_filter=True,                            # keep polygon filtering enabled boolean\n",
    "        remove_zero_sog_vessels=REMOVE_ZERO_SOG_VESSELS,      # use True/False to enable/disable 90% zero-SOG removal\n",
    "        output_sog_in_ms=SOG_IN_MS,                           # convert SOG from knots in m/s (default) boolean\n",
    "        sog_min_knots=SOG_MIN_KNOTS,                          # min SOG in knots to keep (None to disable)\n",
    "        sog_max_knots=SOG_MAX_KNOTS,                          # max SOG in knots to keep (None to disable) \n",
    "        port_locodes_path=file_port_locations,                # path to port locodes CSV\n",
    "        exclude_ports=True,                                   # exclude port areas boolean \n",
    "        verbose=VERBOSE_MODE,                                 # verbose mode boolean\n",
    "    )\n",
    "    \n",
    "    # Free df_raw memory\n",
    "    del df_raw\n",
    "    gc.collect()\n",
    "\n",
    "    # --- Parquet conversion ---\n",
    "    # Save to Parquet by MMSI\n",
    "    ais_to_parquet.save_by_mmsi(\n",
    "        df_filtered,                                             # filtered AIS DataFrame \n",
    "        verbose=VERBOSE_MODE,                                    # verbose mode boolean\n",
    "        output_folder=parquet_folder_path                        # output folder path\n",
    "    )\n",
    "\n",
    "    # Free df_filtered memory\n",
    "    del df_filtered\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfb7e37",
   "metadata": {},
   "source": [
    "## 2) Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50077b83",
   "metadata": {},
   "source": [
    "#### File imports for the pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d240d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import src.pre_proc.pre_processing_utils as pre_processing_utils\n",
    "import src.pre_proc.ais_query as ais_query\n",
    "import src.pre_proc.ais_segment as ais_segment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c417146",
   "metadata": {},
   "source": [
    "#### Library imports for the pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "450bff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23465104",
   "metadata": {},
   "source": [
    "#### Set pre-processing preferences and input configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "149c3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE_MODE = config.VERBOSE_MODE\n",
    "\n",
    "FOLDER_NAME = config.AIS_DATA_FOLDER\n",
    "folder_path = Path(FOLDER_NAME)\n",
    "parquet_folder_path = folder_path / \"parquet\"\n",
    "\n",
    "MAX_TIME_GAP_SEC = config.MAX_TIME_GAP_SEC\n",
    "MAX_TRACK_DURATION_SEC = config.MAX_TRACK_DURATION_SEC\n",
    "MIN_TRACK_DURATION_SEC = config.MIN_TRACK_DURATION_SEC\n",
    "MIN_SEGMENT_LENGTH = config.MIN_SEGMENT_LENGTH\n",
    "\n",
    "MIN_FREQ_POINTS_PER_MIN = config.MIN_FREQ_POINTS_PER_MIN\n",
    "NUMERIC_COLS = config.NUMERIC_COLS\n",
    "\n",
    "TRAIN_START_DATE = config.TRAIN_START_DATE\n",
    "TRAIN_END_DATE = config.TRAIN_END_DATE\n",
    "\n",
    "TEST_START_DATE = config.TEST_START_DATE\n",
    "TEST_END_DATE = config.TEST_END_DATE\n",
    "\n",
    "RESAMPLING_RULE = config.RESAMPLING_RULE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e201661",
   "metadata": {},
   "source": [
    "#### Pre processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "929aae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_pre_processing(dataframe_type: str = \"all\"):\n",
    "\n",
    "    if dataframe_type == \"all\":\n",
    "        main_pre_processing(\"train\")\n",
    "        main_pre_processing(\"test\")\n",
    "        return\n",
    "        \n",
    "    elif dataframe_type == \"train\":\n",
    "        print(f\"[pre_processing] Querying AIS data for training period: {TRAIN_START_DATE} to {TRAIN_END_DATE}\")\n",
    "        # Loading filtered data from parquet files\n",
    "        df = ais_query.query_ais_duckdb(parquet_folder_path, date_start=TRAIN_START_DATE, date_end=TRAIN_END_DATE, verbose=VERBOSE_MODE)\n",
    "        \n",
    "    elif dataframe_type == \"test\":\n",
    "        print(f\"[pre_processing] Querying AIS data for testing period: {TEST_START_DATE} to {TEST_END_DATE}\")\n",
    "        # Loading filtered data from parquet files\n",
    "        df = ais_query.query_ais_duckdb(parquet_folder_path, date_start=TEST_START_DATE, date_end=TEST_END_DATE, verbose=VERBOSE_MODE)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid dataframe_type: {dataframe_type}. Must be 'train' or 'test'.\")\n",
    "    \n",
    "    # Converting COG to sine and cosine components\n",
    "    df = pre_processing_utils.cog_to_sin_cos(df)\n",
    "    \n",
    "    # Dropping unnecessary columns and rows with missing values\n",
    "    df.drop(columns=[ \n",
    "        'Type of mobile', \n",
    "        'COG', \n",
    "        'Date'], inplace=True, errors='ignore')\n",
    "    \n",
    "    # Removing rows with NaN values in essential columns\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Grouping Ship types\n",
    "    commercial_types = [\"Cargo\", \"Tanker\"]\n",
    "    passenger_types = [\"Passenger\", \"Pleasure\", \"Sailing\"]\n",
    "    service_types = [\"Dredging\", \"Law enforcement\", \"Military\", \"Port tender\", \"SAR\", \"Towing\", \"Towing long/wide\",\"Tug\"]\n",
    "    valid_types =  [\"Fishing\", \"Service\", \"Commercial\", \"Passenger\"]\n",
    "\n",
    "    df.loc[df[\"Ship type\"].isin(commercial_types), \"Ship type\"] = \"Commercial\"\n",
    "    df.loc[df[\"Ship type\"].isin(passenger_types), \"Ship type\"] = \"Passenger\"\n",
    "    df.loc[df[\"Ship type\"].isin(service_types), \"Ship type\"] = \"Service\"\n",
    "    df.loc[~df[\"Ship type\"].isin(valid_types), \"Ship type\"] = \"Other\"\n",
    "\n",
    "    print(\"[pre_processing] Ship type counts:\")\n",
    "    print(df[\"Ship type\"].value_counts())\n",
    "    \n",
    "    if VERBOSE_MODE:\n",
    "        print(f\"[pre_processing] DataFrame after dropping unnecessary columns and NaNs: {len(df):,} rows\")\n",
    "\n",
    "    # Segmenting AIS tracks based on time gaps and max duration, filtering short segments\n",
    "    df = ais_segment.segment_ais_tracks(\n",
    "        df,\n",
    "        max_time_gap_sec=MAX_TIME_GAP_SEC,\n",
    "        max_track_duration_sec=MAX_TRACK_DURATION_SEC,\n",
    "        min_track_duration_sec=MIN_TRACK_DURATION_SEC,\n",
    "        min_track_len=MIN_SEGMENT_LENGTH,\n",
    "        verbose=VERBOSE_MODE\n",
    "    )\n",
    "\n",
    "    # Adding segment nr feature\n",
    "    df = pre_processing_utils.add_segment_nr(df)\n",
    "\n",
    "    # Removing segments with low point density\n",
    "    df = pre_processing_utils.remove_notdense_segments(df, min_freq_points_per_min=MIN_FREQ_POINTS_PER_MIN)\n",
    "\n",
    "    # Resampling all tracks to fixed time intervals\n",
    "    df = pre_processing_utils.resample_all_tracks(df, rule=RESAMPLING_RULE)\n",
    "\n",
    "    print(f\"[pre_processing] Number of segments and rows after removing low-density segments and resampling: {df['Segment_nr'].nunique():,} segments, {len(df):,} rows\")\n",
    "    # Normalizing numeric columns\n",
    "    df, mean, std = pre_processing_utils.normalize_df(df, NUMERIC_COLS)\n",
    "\n",
    "    # Ship type labeling (mapping to be used later)\n",
    "    df, ship_type_to_id = pre_processing_utils.label_ship_types(df)\n",
    "    \n",
    "    # Saving pre-processed DataFrame\n",
    "    if dataframe_type == \"train\":\n",
    "        print(f\"[pre_processing] Saving pre-processed DataFrame to {config.PRE_PROCESSING_DF_TRAIN_PATH}...\")\n",
    "        output_path = config.PRE_PROCESSING_DF_TRAIN_PATH\n",
    "        metadata_path = config.PRE_PROCESSING_METADATA_TRAIN_PATH\n",
    "    else:\n",
    "        print(f\"[pre_processing] Saving pre-processed DataFrame to {config.PRE_PROCESSING_DF_TEST_PATH}...\")\n",
    "        output_path = config.PRE_PROCESSING_DF_TEST_PATH\n",
    "        metadata_path = config.PRE_PROCESSING_METADATA_TEST_PATH\n",
    "\n",
    "    if VERBOSE_MODE: print(f\"[pre_processing] Columns of pre-processed DataFrame:\\n{df.columns.tolist()}\")\n",
    "    Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_parquet(output_path, index=False)\n",
    "\n",
    "    # Saving preprocessing metadata\n",
    "    if VERBOSE_MODE: print(f\"[pre_processing] Saving preprocessing metadata to {metadata_path}...\")\n",
    "    meta = {\n",
    "        \"mean\": mean.tolist(),\n",
    "        \"std\": std.tolist(),\n",
    "        \"ship_type_to_id\": ship_type_to_id\n",
    "    }\n",
    "\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        json.dump(meta, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756cf852",
   "metadata": {},
   "source": [
    "#### Pre processing script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "597faf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pre_processing] Querying AIS data for training period: 2025-08-01 to 2025-08-28\n",
      "[ais_query] Querying parquet files from: ais-data/parquet  from date 2025-08-01  to date  2025-08-28\n",
      "[ais_query] 4,845,439 rows, 3,060 vessels, from date 2025-08-01 to date 2025-08-28\n",
      "[pre_processing] Ship type counts:\n",
      "Ship type\n",
      "Commercial    1910924\n",
      "Fishing       1681786\n",
      "Passenger      962508\n",
      "Service        157397\n",
      "Other          132824\n",
      "Name: count, dtype: int64\n",
      "[pre_processing] DataFrame after dropping unnecessary columns and NaNs: 4,845,439 rows\n",
      "[segment_ais_tracks] Starting with 4,845,439 rows, 3,060 unique vessels\n",
      "[segment_ais_tracks] After segment-level filter: 4,838,589 rows, 7,331 segments\n",
      "[pre_processing] Number of segments after removing low-density segments: 7,311\n",
      "[pre_processing] Saving pre-processed DataFrame to ais-data/df_preprocessed/pre_processed_df_train.parquet...\n",
      "[pre_processing] Columns of pre-processed DataFrame:\n",
      "['Segment_nr', 'Timestamp', 'Latitude', 'Longitude', 'SOG', 'COG_sin', 'COG_cos', 'TrackID', 'MMSI', 'ShipTypeID']\n",
      "[pre_processing] Saving preprocessing metadata to ais-data/df_preprocessed/pre_processing_metadata_train.json...\n"
     ]
    }
   ],
   "source": [
    "main_pre_processing(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61d81e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pre_processing] Querying AIS data for testing period: 2025-08-29 to 2025-08-30\n",
      "[ais_query] Querying parquet files from: ais-data/parquet  from date 2025-08-29  to date  2025-08-30\n",
      "[ais_query] 249,888 rows, 358 vessels, from date 2025-08-29 to date 2025-08-30\n",
      "[pre_processing] Ship type counts:\n",
      "Ship type\n",
      "Commercial    140651\n",
      "Passenger      45631\n",
      "Fishing        44189\n",
      "Service        13655\n",
      "Other           5762\n",
      "Name: count, dtype: int64\n",
      "[pre_processing] DataFrame after dropping unnecessary columns and NaNs: 249,888 rows\n",
      "[segment_ais_tracks] Starting with 249,888 rows, 358 unique vessels\n",
      "[segment_ais_tracks] After segment-level filter: 249,208 rows, 427 segments\n",
      "[pre_processing] Number of segments and rows after removing low-density segments and resampling: 411 segments, 43,224 rows\n",
      "[pre_processing] Saving pre-processed DataFrame to ais-data/df_preprocessed/pre_processed_df_test.parquet...\n",
      "[pre_processing] Columns of pre-processed DataFrame:\n",
      "['Segment_nr', 'Timestamp', 'Latitude', 'Longitude', 'SOG', 'COG_sin', 'COG_cos', 'TrackID', 'MMSI', 'ShipTypeID']\n",
      "[pre_processing] Saving preprocessing metadata to ais-data/df_preprocessed/pre_processing_metadata_test.json...\n"
     ]
    }
   ],
   "source": [
    "main_pre_processing(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7724caf9",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f656cc",
   "metadata": {},
   "source": [
    "#### File imports for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2de52b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d73047b",
   "metadata": {},
   "source": [
    "#### Library imports for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bc4c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "927b9e0b",
   "metadata": {},
   "source": [
    "#### Set training preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e19d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9953ac75",
   "metadata": {},
   "source": [
    "#### Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7388c647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dca7304f",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6fb787",
   "metadata": {},
   "source": [
    "#### File imports for the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e75767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acd90563",
   "metadata": {},
   "source": [
    "#### Library imports for the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c86bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df15213e",
   "metadata": {},
   "source": [
    "#### Set evaluation preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb9e93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b0d3719",
   "metadata": {},
   "source": [
    "#### Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb45a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb69a421",
   "metadata": {},
   "source": [
    "## Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6993541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
