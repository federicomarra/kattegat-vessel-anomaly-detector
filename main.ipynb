{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e568f0d6",
   "metadata": {},
   "source": [
    "# dark-vessel-hunter\n",
    "DTU Deep Learning project 29, group 80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425814a0",
   "metadata": {},
   "source": [
    "## Required libraries installation\n",
    "Run this in your terminal before executing this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c6f609e",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datetime in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (5.5)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: pathlib in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (2.32.5)\n",
      "Requirement already satisfied: zipfile36 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (0.1.3)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (2.3.2)\n",
      "Requirement already satisfied: pyarrow in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (19.0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (1.7.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (1.26.4)\n",
      "Requirement already satisfied: seaborn in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (0.13.2)\n",
      "Requirement already satisfied: shapely in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (2.1.2)\n",
      "Requirement already satisfied: folium in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (0.20.0)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (3.10.6)\n",
      "Requirement already satisfied: fastparquet in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (2024.11.0)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (6.0.3)\n",
      "Requirement already satisfied: typing in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from -r requirements.txt (line 16)) (3.7.4.3)\n",
      "Requirement already satisfied: duckdb in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from -r requirements.txt (line 17)) (1.4.2)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from -r requirements.txt (line 18)) (0.24.1)\n",
      "Requirement already satisfied: zope.interface in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from datetime->-r requirements.txt (line 1)) (8.1)\n",
      "Requirement already satisfied: pytz in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from datetime->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from requests->-r requirements.txt (line 4)) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from requests->-r requirements.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from requests->-r requirements.txt (line 4)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from requests->-r requirements.txt (line 4)) (2025.10.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 6)) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 8)) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 8)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 8)) (3.6.0)\n",
      "Requirement already satisfied: branca>=0.6.0 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from folium->-r requirements.txt (line 12)) (0.8.2)\n",
      "Requirement already satisfied: jinja2>=2.9 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from folium->-r requirements.txt (line 12)) (3.1.6)\n",
      "Requirement already satisfied: xyzservices in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from folium->-r requirements.txt (line 12)) (2025.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 13)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 13)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 13)) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 13)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 13)) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 13)) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 13)) (3.2.0)\n",
      "Requirement already satisfied: cramjam>=2.3 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from fastparquet->-r requirements.txt (line 14)) (2.11.0)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from fastparquet->-r requirements.txt (line 14)) (2024.12.0)\n",
      "Requirement already satisfied: torch==2.9.1 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from torchvision->-r requirements.txt (line 18)) (2.9.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from torch==2.9.1->torchvision->-r requirements.txt (line 18)) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from torch==2.9.1->torchvision->-r requirements.txt (line 18)) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from torch==2.9.1->torchvision->-r requirements.txt (line 18)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from torch==2.9.1->torchvision->-r requirements.txt (line 18)) (3.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from jinja2>=2.9->folium->-r requirements.txt (line 12)) (3.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 6)) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/dl/lib/python3.11/site-packages (from sympy>=1.13.3->torch==2.9.1->torchvision->-r requirements.txt (line 18)) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccd44da",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c347b624",
   "metadata": {},
   "source": [
    "#### File imports for the data script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c203ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import src.data.ais_downloader as ais_downloader\n",
    "import src.data.ais_filtering as ais_filtering\n",
    "import src.data.ais_reader as ais_reader\n",
    "import src.data.ais_to_parquet as ais_to_parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3813a859",
   "metadata": {},
   "source": [
    "#### Library imports for the data script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc178db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65675b5f",
   "metadata": {},
   "source": [
    "#### Set data preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c341eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = \"2025-11-01\"\n",
    "END_DATE   = \"2025-11-03\"\n",
    "\n",
    "FOLDER_NAME = config.AIS_DATA_FOLDER\n",
    "DELETE_DOWNLOADED_CSV = False\n",
    "VERBOSE_MODE = True\n",
    "\n",
    "VESSEL_AIS_CLASS = (\"Class A\", \"Class B\")\n",
    "\n",
    "MIN_SEGMENT_LENGTH = 30     # datapoints\n",
    "MAX_TIME_GAP_SEC = 30       # seconds\n",
    "\n",
    "# Bounding Box to prefilter AIS data [lat_max, lon_min, lat_min, lon_max]\n",
    "bbox = [57.58, 10.5, 57.12, 11.92]\n",
    "\n",
    "# Polygon coordinates for precise Area of Interest (AOI) filtering (lon, lat)\n",
    "polygon_coords = [\n",
    "    (10.5162, 57.3500),  # coast top left (lon, lat)\n",
    "    (10.9314, 57.5120),  # sea top left\n",
    "    (11.5128, 57.5785),  # sea top right\n",
    "    (11.9132, 57.5230),  # top right (Swedish coast)\n",
    "    (11.9189, 57.4078),  # bottom right (Swedish coast)\n",
    "    (11.2133, 57.1389),  # sea bottom right\n",
    "    (11.0067, 57.1352),  # sea bottom left\n",
    "    (10.5400, 57.1880),  # coast bottom left\n",
    "    (10.5162, 57.3500),  # close polygon\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9d8db5",
   "metadata": {},
   "source": [
    "#### Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e746873c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2a99188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 0/3 [00:00<?, ?file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing date: 2025-11-01\n",
      "Skipping 2025-11-01 download: already present in ais-data/csv folder\n",
      " Read AIS data: 988,647 rows within bbox,  241 unique vessels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 0/3 [00:02<?, ?file/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m DELETE_DOWNLOADED_CSV: csv_path.unlink(missing_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# --- Filter and split ---\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Filter AIS data, keeping Class A and Class B by default,\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m df_filtered = \u001b[43mais_filtering\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfilter_ais_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpolygon_coords\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpolygon_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallowed_mobile_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mVESSEL_AIS_CLASS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                          \u001b[49m\u001b[38;5;66;43;03m# select bbox \u001b[39;49;00m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapply_polygon_filter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# keep polygon filtering enabled boolean\u001b[39;49;00m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mremove_zero_sog_vessels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# use True/False to enable/disable 90% zero-SOG removal\u001b[39;49;00m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43msog_in_knots\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# convert SOG from knots in m/s (default) boolean\u001b[39;49;00m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mport_locodes_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile_port_locations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexclude_ports\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# exclude port areas boolean \u001b[39;49;00m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mVERBOSE_MODE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# verbose mode boolean\u001b[39;49;00m\n\u001b[32m     44\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# --- Parquet conversion ---\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Segment and save to Parquet by MMSI\u001b[39;00m\n\u001b[32m     48\u001b[39m df_seg = ais_to_parquet.segment_ais_tracks(df_filtered, min_track_len=MIN_SEGMENT_LENGTH, max_time_gap_sec=MAX_TIME_GAP_SEC, verbose=VERBOSE_MODE)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/dl-dark-vessel-hunter/src/data/ais_filtering.py:320\u001b[39m, in \u001b[36mfilter_ais_df\u001b[39m\u001b[34m(df, polygon_coords, allowed_mobile_types, bbox, apply_polygon_filter, remove_zero_sog_vessels, sog_in_knots, port_locodes_path, exclude_ports, verbose)\u001b[39m\n\u001b[32m    318\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mMMSI\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mMMSI\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).str.strip()\n\u001b[32m    319\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mTimestamp\u001b[39m\u001b[33m\"\u001b[39m] = pd.to_datetime(df[\u001b[33m\"\u001b[39m\u001b[33mTimestamp\u001b[39m\u001b[33m\"\u001b[39m], errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m df = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTimestamp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[32m    323\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    324\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m [filter_ais_df] Before filtering: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    325\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[33m'\u001b[39m\u001b[33mMMSI\u001b[39m\u001b[33m'\u001b[39m].nunique()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m vessels\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    326\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/dl/lib/python3.11/site-packages/pandas/core/frame.py:6693\u001b[39m, in \u001b[36mDataFrame.dropna\u001b[39m\u001b[34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[39m\n\u001b[32m   6690\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minvalid how option: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   6692\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.all(mask):\n\u001b[32m-> \u001b[39m\u001b[32m6693\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   6694\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6695\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.loc(axis=axis)[mask]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/dl/lib/python3.11/site-packages/pandas/core/generic.py:6830\u001b[39m, in \u001b[36mNDFrame.copy\u001b[39m\u001b[34m(self, deep)\u001b[39m\n\u001b[32m   6681\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m   6682\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m, deep: bool_t | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mTrue\u001b[39;00m) -> Self:\n\u001b[32m   6683\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   6684\u001b[39m \u001b[33;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[32m   6685\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   6828\u001b[39m \u001b[33;03m    dtype: int64\u001b[39;00m\n\u001b[32m   6829\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6830\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6831\u001b[39m     \u001b[38;5;28mself\u001b[39m._clear_item_cache()\n\u001b[32m   6832\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(data, axes=data.axes).__finalize__(\n\u001b[32m   6833\u001b[39m         \u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mcopy\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6834\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/dl/lib/python3.11/site-packages/pandas/core/internals/managers.py:593\u001b[39m, in \u001b[36mBaseBlockManager.copy\u001b[39m\u001b[34m(self, deep)\u001b[39m\n\u001b[32m    590\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    591\u001b[39m         new_axes = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.axes)\n\u001b[32m--> \u001b[39m\u001b[32m593\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcopy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    594\u001b[39m res.axes = new_axes\n\u001b[32m    596\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ndim > \u001b[32m1\u001b[39m:\n\u001b[32m    597\u001b[39m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/dl/lib/python3.11/site-packages/pandas/core/internals/managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/dl/lib/python3.11/site-packages/pandas/core/internals/blocks.py:822\u001b[39m, in \u001b[36mBlock.copy\u001b[39m\u001b[34m(self, deep)\u001b[39m\n\u001b[32m    820\u001b[39m refs: BlockValuesRefs | \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m     values = \u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    823\u001b[39m     refs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- Create paths ---\n",
    "folder_path = Path(FOLDER_NAME)\n",
    "folder_path.mkdir(parents=True, exist_ok=True)\n",
    "csv_folder_path = folder_path / \"csv\"\n",
    "csv_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "parquet_folder_path = folder_path / \"parquet\"\n",
    "parquet_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "file_port_locations = folder_path / \"port_locodes.csv\"\n",
    "\n",
    "\n",
    "# --- If you want to download all csv files before, uncomment the line below ---\n",
    "# ais_downloader.download_multiple_ais_data(START_DATE, END_DATE, folder_path)\n",
    "\n",
    "# --- Build the schedule of download string dates ---\n",
    "dates = ais_downloader.get_work_dates(START_DATE, END_DATE, csv_folder_path, filter=False)\n",
    "\n",
    "# --- Iterate with tqdm and download, unzip and delete ---\n",
    "for day in tqdm(dates, desc=f\"Processing data\", unit=\"file\" ):\n",
    "    tag = f\"{day:%Y-%m}\" if day < date.fromisoformat(\"2024-03-01\") else f\"{day:%Y-%m-%d}\"\n",
    "    print(f\"\\nProcessing date: {tag}\")\n",
    "\n",
    "    # --- Download one day ---\n",
    "    csv_path = ais_downloader.download_one_ais_data(day, csv_folder_path)\n",
    "    \n",
    "    # --- Load CSV into DataFrame ---\n",
    "    df_raw = ais_reader.read_single_ais_df(csv_path, bbox, verbose=VERBOSE_MODE)\n",
    "    # --- Optionally delete the downloaded CSV file ---\n",
    "    if DELETE_DOWNLOADED_CSV: csv_path.unlink(missing_ok=True)\n",
    "    \n",
    "    # --- Filter and split ---\n",
    "    # Filter AIS data, keeping Class A and Class B by default,\n",
    "    df_filtered = ais_filtering.filter_ais_df(\n",
    "        df_raw,\n",
    "        polygon_coords=polygon_coords,\n",
    "        allowed_mobile_types=VESSEL_AIS_CLASS,\n",
    "        bbox=bbox,                          # select bbox \n",
    "        apply_polygon_filter=True,          # keep polygon filtering enabled boolean\n",
    "        remove_zero_sog_vessels=False,      # use True/False to enable/disable 90% zero-SOG removal\n",
    "        sog_in_knots=False,                 # convert SOG from knots in m/s (default) boolean\n",
    "        port_locodes_path=file_port_locations,\n",
    "        exclude_ports=True,                 # exclude port areas boolean \n",
    "        verbose=VERBOSE_MODE,               # verbose mode boolean\n",
    "    )\n",
    "\n",
    "    # --- Parquet conversion ---\n",
    "    # Segment and save to Parquet by MMSI\n",
    "    df_seg = ais_to_parquet.segment_ais_tracks(df_filtered, min_track_len=MIN_SEGMENT_LENGTH, max_time_gap_sec=MAX_TIME_GAP_SEC, verbose=VERBOSE_MODE)\n",
    "    # Save segmented data to Parquet files\n",
    "    ais_to_parquet.save_by_mmsi(df_seg, verbose=VERBOSE_MODE, output_folder=parquet_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfb7e37",
   "metadata": {},
   "source": [
    "## Pre processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50077b83",
   "metadata": {},
   "source": [
    "#### File imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d240d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c417146",
   "metadata": {},
   "source": [
    "#### Library imports for the pre processing script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450bff08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23465104",
   "metadata": {},
   "source": [
    "#### Set pre processing preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149c3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_NAME = config.AIS_DATA_FOLDER\n",
    "folder_path = Path(FOLDER_NAME)\n",
    "parquet_folder_path = folder_path / \"parquet\"\n",
    "\n",
    "SEGMENT_MAX_LENGTH = config.SEGMENT_MAX_LENGTH\n",
    "\n",
    "NUMERIC_COLS = config.NUMERIC_COLS\n",
    "# if u want to do it withouth a end date comment next line\n",
    "TRAIN_START_DATE = config.TRAIN_START_DATE\n",
    "TRAIN_END_DATE = config.TRAIN_END_DATE\n",
    "\n",
    "TEST_START_DATE = config.TEST_START_DATE\n",
    "TEST_END_DATE = config.TEST_END_DATE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
