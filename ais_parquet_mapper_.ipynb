{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5af018c0",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aed674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Optional, Sequence, Union, List\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import folium\n",
    "\n",
    "def query_ais_duckdb(\n",
    "    root_path: Union[str, Path] = \"ais-data-parquet\",\n",
    "    dates: Optional[Union[str, Sequence[str]]] = None,\n",
    "    mmsi: Optional[Union[str, Sequence[str]]] = None,\n",
    "    segments: Optional[Union[int, Sequence[int]]] = None,\n",
    "    columns: Optional[Sequence[str]] = None,\n",
    "    verbose: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fast query helper using DuckDB to read AIS data from the partitioned\n",
    "    parquet dataset generated by `ais_to_parquet`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    root_path : str or Path, optional\n",
    "        Root directory of the parquet dataset (default: \"ais_data_parquet\").\n",
    "    dates : str or list[str], optional\n",
    "        Date(s) to filter on (e.g. \"2025-11-05\", or [\"2025-11-05\", \"2025-11-06\"]).\n",
    "        If None, no date filter is applied.\n",
    "    mmsi : str or list[str], optional\n",
    "        MMSI or list of MMSIs to filter on. If None, no MMSI filter is applied.\n",
    "    segments : int or list[int], optional\n",
    "        Segment ID(s) to filter on. If None, no segment filter is applied.\n",
    "    columns : list[str], optional\n",
    "        Subset of columns to select. If None, selects all columns (\"*\").\n",
    "    verbose : bool, optional\n",
    "        If True, prints the generated SQL query.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Result of the DuckDB query as a pandas DataFrame.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> df = query_ais_duckdb(dates=\"2025-11-05\")\n",
    "    >>> df = query_ais_duckdb(dates=\"2025-11-05\", mmsi=\"219000123\")\n",
    "    >>> df = query_ais_duckdb(\n",
    "    ...     dates=[\"2025-11-05\", \"2025-11-06\"],\n",
    "    ...     mmsi=[\"219000123\", \"219000456\"],\n",
    "    ...     columns=[\"MMSI\", \"Timestamp\", \"Latitude\", \"Longitude\"]\n",
    "    ... )\n",
    "    \"\"\"\n",
    "    root_path = Path(root_path)\n",
    "    if not root_path.exists():\n",
    "        raise FileNotFoundError(f\"No parquet dataset found at: {root_path}\")\n",
    "\n",
    "    # Normalization helpers\n",
    "    def _to_list(x) -> Optional[List]:\n",
    "        if x is None:\n",
    "            return None\n",
    "        if isinstance(x, (str, int)):\n",
    "            return [x]\n",
    "        return list(x)\n",
    "\n",
    "    def _sql_list_str(values: Sequence[str]) -> str:\n",
    "        return \", \".join(f\"'{v}'\" for v in values)\n",
    "\n",
    "    def _sql_list_int(values: Sequence[int]) -> str:\n",
    "        return \", \".join(str(v) for v in values)\n",
    "\n",
    "    dates_list = _to_list(dates)\n",
    "    mmsi_list = _to_list(mmsi)\n",
    "    segments_list = _to_list(segments)\n",
    "\n",
    "    # Columns\n",
    "    if columns is None:\n",
    "        col_expr = \"*\"\n",
    "    else:\n",
    "        col_expr = \", \".join(columns)\n",
    "\n",
    "    parquet_glob = str(root_path / \"**\" / \"*.parquet\")\n",
    "\n",
    "    sql = f\"SELECT {col_expr} FROM read_parquet('{parquet_glob}') WHERE 1=1\"\n",
    "\n",
    "    if dates_list is not None:\n",
    "        sql += f\" AND Date IN ({_sql_list_str([str(d) for d in dates_list])})\"\n",
    "\n",
    "    if mmsi_list is not None:\n",
    "        sql += f\" AND MMSI IN ({_sql_list_str([str(m) for m in mmsi_list])})\"\n",
    "\n",
    "    if segments_list is not None:\n",
    "        sql += f\" AND Segment IN ({_sql_list_int([int(s) for s in segments_list])})\"\n",
    "\n",
    "    if verbose:\n",
    "        print(\"[query_ais_duckdb] SQL:\\n\", sql)\n",
    "\n",
    "    con = duckdb.connect(database=\":memory:\")\n",
    "    df = con.execute(sql).df()\n",
    "    con.close()\n",
    "    return df\n",
    "\n",
    "def make_ais_folium_map(\n",
    "    date: str,\n",
    "    root_path: Union[str, Path] = \"ais-data-parquet\",\n",
    "    mmsi: Optional[Union[str, Sequence[str]]] = None,\n",
    "    tiles: str = \"CartoDB positron\",\n",
    "    zoom_start: int = 8,\n",
    "    verbose: bool = False,\n",
    ") -> folium.Map:\n",
    "    \"\"\"\n",
    "    Create a Folium map of AIS tracks for a given date, optionally for only a\n",
    "    subset of vessels (MMSIs).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    date : str\n",
    "        Date to visualize (e.g. \"2025-11-05\").\n",
    "    root_path : str or Path, optional\n",
    "        Root directory of the parquet dataset (default: \"ais_data_parquet\").\n",
    "    mmsi : str or list[str], optional\n",
    "        MMSI(s) to include. If None, includes all vessels on that date.\n",
    "    tiles : str, optional\n",
    "        Folium tiles style (default: \"CartoDB positron\").\n",
    "    zoom_start : int, optional\n",
    "        Initial zoom level for the map.\n",
    "    verbose : bool, optional\n",
    "        Print some info about the data being plotted.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    folium.Map\n",
    "        A Folium map with vessel tracks drawn as polylines.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> m = make_ais_folium_map(\"2025-11-05\")\n",
    "    >>> m.save(\"ais_tracks_2025-11-05.html\")\n",
    "    >>>\n",
    "    >>> m = make_ais_folium_map(\"2025-11-05\", mmsi=[\"219000123\", \"219000456\"])\n",
    "    \"\"\"\n",
    "    # Query only what we need\n",
    "    df = query_ais_duckdb(\n",
    "        root_path=root_path,\n",
    "        dates=date,\n",
    "        mmsi=mmsi,\n",
    "        columns=[\"MMSI\", \"Timestamp\", \"Latitude\", \"Longitude\", \"Segment\"],\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"No AIS data found for date={date} and mmsi={mmsi}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"[make_ais_folium_map] Loaded {len(df):,} rows, \"\n",
    "            f\"{df['MMSI'].nunique():,} vessels\"\n",
    "        )\n",
    "\n",
    "    # Ensure proper dtypes / ordering\n",
    "    df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"])\n",
    "    df = df.sort_values([\"MMSI\", \"Segment\", \"Timestamp\"])\n",
    "\n",
    "    # Map center: mean of all positions\n",
    "    center_lat = df[\"Latitude\"].mean()\n",
    "    center_lon = df[\"Longitude\"].mean()\n",
    "\n",
    "    m = folium.Map(location=[center_lat, center_lon], zoom_start=zoom_start, tiles=tiles)\n",
    "\n",
    "    # Group by vessel (and optionally segment)\n",
    "    for (mmsi_val, seg_val), g in df.groupby([\"MMSI\", \"Segment\"]):\n",
    "        coords = g[[\"Latitude\", \"Longitude\"]].to_numpy().tolist()\n",
    "        if len(coords) < 2:\n",
    "            continue  # not enough points to draw a line\n",
    "\n",
    "        tooltip = f\"MMSI: {mmsi_val}, Segment: {seg_val}\"\n",
    "        folium.PolyLine(\n",
    "            locations=coords,\n",
    "            weight=2,\n",
    "            opacity=0.8,\n",
    "            tooltip=tooltip,\n",
    "        ).add_to(m)\n",
    "\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37c86b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[query_ais_duckdb] SQL:\n",
      " SELECT MMSI, Timestamp, Latitude, Longitude, Segment FROM read_parquet('ais-data-parquet\\**\\*.parquet') WHERE 1=1 AND Date IN ('2025-11-05')\n",
      "[make_ais_folium_map] Loaded 184,183 rows, 123 vessels\n"
     ]
    }
   ],
   "source": [
    "m = make_ais_folium_map(\"2025-11-05\", verbose=True)\n",
    "m.save(\"ais_tracks_2025-11-05.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4207b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[query_ais_duckdb] SQL:\n",
      " SELECT MMSI, Timestamp, Latitude, Longitude, Segment FROM read_parquet('ais-data-parquet\\**\\*.parquet') WHERE 1=1 AND Date IN ('2025-11-02') AND MMSI IN ('219006113', '219009229')\n",
      "[make_ais_folium_map] Loaded 18,843 rows, 2 vessels\n"
     ]
    }
   ],
   "source": [
    "m = make_ais_folium_map(\n",
    "    date=\"2025-11-02\",\n",
    "    mmsi=[\"219006113\", \"219009229\"],\n",
    "    verbose=True,\n",
    ")\n",
    "m.save(\"ais_tracks_subset_2025-11-05.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b95d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 routes.\n",
      "Saved map as dkcpc_lines_bbox.html\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
