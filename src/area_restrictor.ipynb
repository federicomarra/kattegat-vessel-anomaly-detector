{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33cfbad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf564568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.data.ais_filtering as ais_filtering\n",
    "import src.utils.ais_utils as ais_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8e7740",
   "metadata": {},
   "source": [
    "## FUNCTIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "499aabc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_cleaning_pipeline(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df = df[df[\"Type of mobile\"].isin([\"Class A\", \"Class B\"])].drop(columns=[\"Type of mobile\"])\n",
    "\n",
    "    df = df.rename(columns={\"# Timestamp\": \"Timestamp\"})\n",
    "    df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"], format=\"%d/%m/%Y %H:%M:%S\", errors=\"coerce\")\n",
    "\n",
    "    df = df.drop_duplicates([\"Timestamp\", \"MMSI\", ], keep=\"first\")\n",
    "    df = df.drop(columns=df.columns[-5:])\n",
    "\n",
    "    knots_to_ms = 0.514444\n",
    "    df[\"SOG\"] = knots_to_ms * df[\"SOG\"]\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def quick_summary(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Generate a quick summary of the AIS data in the DataFrame.\n",
    "    Args:\n",
    "        df: DataFrame with AIS data, must contain 'MMSI', 'Timestamp', 'Latitude', 'Longitude' columns.\n",
    "        \n",
    "    Returns:\n",
    "        None: Prints summary statistics.\n",
    "        \"\"\"\n",
    "    # Number of unique vessels\n",
    "    num_vessels = int(df['MMSI'].nunique())\n",
    "    df = df.rename(columns={\"# Timestamp\": \"Timestamp\"})\n",
    "    df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"], format=\"%d/%m/%Y %H:%M:%S\", errors=\"coerce\")\n",
    "\n",
    "    # Spatial extent\n",
    "    lat_min, lat_max = df['Latitude'].min(), df['Latitude'].max()\n",
    "    lon_min, lon_max = df['Longitude'].min(), df['Longitude'].max()\n",
    "    centroid_lat, centroid_lon = df['Latitude'].mean(), df['Longitude'].mean()\n",
    "\n",
    "    # Messages per vessel\n",
    "    msgs_per_vessel = df.groupby('MMSI').size()\n",
    "    msgs_stats = msgs_per_vessel.describe().to_dict()\n",
    "    top_10_vessels = msgs_per_vessel.sort_values(ascending=False).head(10)\n",
    "\n",
    "    # Print concise overview\n",
    "    print(f\"Number of unique vessels: {num_vessels}\")\n",
    "    print(f\"Latitude range: {lat_min:.6f} -- {lat_max:.6f}\")\n",
    "    print(f\"Longitude range: {lon_min:.6f} -- {lon_max:.6f}\")\n",
    "    print(f\"Centroid (lat, lon): ({centroid_lat:.6f}, {centroid_lon:.6f})\")\n",
    "    print(\"\\nMessages per vessel (summary):\")\n",
    "    for k, v in msgs_stats.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print(\"\\nTop 10 vessels by number of messages (MMSI: count):\")\n",
    "    print(top_10_vessels.to_string())\n",
    "\n",
    "\n",
    "def singularize_vessels(df, mmsi_col=\"MMSI\", start_col_index=11, join_conflicts=True, sep=\" | \"):\n",
    "    cols = list(df.columns[start_col_index:])\n",
    "    if mmsi_col not in df.columns:\n",
    "        raise KeyError(f\"MMSI column '{mmsi_col}' not found in dataframe\")\n",
    "\n",
    "    def _agg(series):\n",
    "        vals = series.dropna().unique().tolist()\n",
    "        if len(vals) == 0:\n",
    "            return np.nan\n",
    "        if len(vals) == 1:\n",
    "            return vals[0]\n",
    "        if join_conflicts:\n",
    "            return sep.join(map(str, vals))\n",
    "        return vals\n",
    "\n",
    "    grouped = df.groupby(mmsi_col)[cols].agg(_agg).reset_index()\n",
    "    ordered_cols = [mmsi_col] + cols\n",
    "    return grouped[ordered_cols]\n",
    "\n",
    "def filter_inside_square(df, bbox) -> pd.DataFrame:\n",
    "    north, west, south, east = bbox\n",
    "    df = df[(df[\"Latitude\"] <= north) & (df[\"Latitude\"] >= south) & (df[\"Longitude\"] >= west) & (df[\"Longitude\"] <= east)] \n",
    "    return df\n",
    "\n",
    "def is_inside_polygon(lat, lon, polygon_coords):\n",
    "    \"\"\"\n",
    "    Check if a point (lat, lon) is inside a polygon.\n",
    "    \n",
    "    Args:\n",
    "        lat: Latitude\n",
    "        lon: Longitude\n",
    "        polygon_coords: List of (lon, lat) tuples defining polygon vertices\n",
    "        \n",
    "    Returns:\n",
    "        Boolean: True if point is inside polygon\n",
    "    \"\"\"\n",
    "    point = Point(lat, lon)\n",
    "    polygon = Polygon(polygon_coords)\n",
    "    return polygon.contains(point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9753f2d",
   "metadata": {},
   "source": [
    "# ðŸ›°ï¸ AIS Data Filtering and Preprocessing â€” Kattegat Submarine Cable Area\n",
    "\n",
    "This notebook documents the initial steps of data preparation for the AIS anomaly detection project focusing on the submarine communication cables in the Kattegat area (Denmarkâ€“Sweden).\n",
    "\n",
    "The goal is to isolate AIS data within a defined polygon surrounding three specific cable routes (**GC2**, **Kattegat 2A**, and **Kattegat 2B**) and perform preliminary cleaning and filtering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b2b51d",
   "metadata": {},
   "source": [
    "## ðŸ§­ Area of Interest Definition\n",
    "\n",
    "We are interested in identifying potential anomalous or risky vessel behaviors near submarine cables.\n",
    "\n",
    "By Danish law, a 200 m protection zone exists on each side of these cables, but in this study we extend the inspection zone to **5 km** to capture behavioral precursors such as early anchoring, trawling, or route deviations before ships enter the restricted corridor.\n",
    "\n",
    "The polygon defining our area of interest was manually approximated based on the **DKCPC map**.\n",
    "\n",
    "It includes a section of the Danish coast near Saeby and extends to the Swedish side around Lerkil, covering the main cable routes.  \n",
    "The coordinates are stored as `(latitude, longitude)` pairs and define an octagonal region enclosing the study zone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fbd739",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial filter on bounding box (take northest and southest, westest and eastest points):\n",
    "bbox = [57.58, 10.5, 57.12, 11.92]  # north, west, south, east\n",
    "# Define polygon coordinates as (lat, lon)\n",
    "polygon_coords = [\n",
    "    (57.3500, 10.5162),  # coast top left\n",
    "    (57.5120, 10.9314),  # sea top left\n",
    "    (57.5785, 11.5128),  # sea top right\n",
    "    (57.5230, 11.9132),  # top right (Swedish coast)\n",
    "    (57.4078, 11.9189),  # bottom right (Swedish coast)\n",
    "    (57.1389, 11.2133),  # sea bottom right\n",
    "    (57.1352, 11.0067),  # sea bottom left\n",
    "    (57.1880, 10.5400),  # coast bottom left\n",
    "    (57.3500, 10.5162),  # close polygon (duplicate of first)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c018791d",
   "metadata": {},
   "source": [
    "## âš™ï¸ Data Loading\n",
    "\n",
    "In this step, AIS data (in CSV format) is loaded and receives a first hand cleaning 10% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f42f82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_28 = pd.read_csv(\"ais-data/aisdk-2025-10-28.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c7078",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"No filtering: {len(df_28):,} rows, {df_28['MMSI'].nunique():,} unique vessels, {df_28.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5096e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = mini_cleaning_pipeline(df_28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dffe131",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" Initial filtering complete: {len(df_cleaned):,} rows, {df_cleaned['MMSI'].nunique():,} unique vessels, {df_cleaned.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31bc42a",
   "metadata": {},
   "source": [
    "## ðŸ“ SQUARE Filtering\n",
    "\n",
    "The box coordinates defined earlier are used to filter the AIS dataset.\n",
    "Each point is checked to determine whether it falls inside the box using simple operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bee294",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inside_square = filter_inside_square(df_cleaned, bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96823bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" Bounding box filtering complete: {len(df_inside_square):,} rows, {df_inside_square['MMSI'].nunique():,} unique vessels, {df_inside_square.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bcd40e",
   "metadata": {},
   "source": [
    "## ðŸ“ Polygon Filtering\n",
    "\n",
    "The polygon coordinates defined earlier are used to filter the AIS dataset.\n",
    "\n",
    "Each point is checked to determine whether it falls inside the polygon using geometric operations (e.g. with the `shapely` library).\n",
    "\n",
    "The resulting dataset contains only positions **within the defined Kattegat zone**, roughly **3â€“4 %** of the original AIS dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb9703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inside_poly = df_inside_square[\n",
    "    df_inside_square.apply(lambda row: is_inside_polygon(row['Latitude'], row['Longitude'], polygon_coords), axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee428d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" Polygon filtering complete: {len(df_inside_poly):,} rows, {df_inside_poly['MMSI'].nunique():,} unique vessels, {df_inside_poly.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69df1ab7",
   "metadata": {},
   "source": [
    "## ðŸ“Š Data Overview After Filtering\n",
    "\n",
    "We summarize the filtered dataset:\n",
    "\n",
    "- Number of unique vessels  \n",
    "- Time coverage of the subset  \n",
    "- Spatial extent and approximate number of messages per vessel  \n",
    "\n",
    "This quick overview helps confirm that the filtering worked as expected and that the dataset is representative of the study area.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c77ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_summary(df_inside_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43968802",
   "metadata": {},
   "source": [
    "# USING SUMMARY FUNCTIONS TO FILTER AND DIVIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7470c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day = pd.read_csv(\"ais-data/aisdk-2025-11-03.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aa54a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering: 16,050,529 rows, 3,151 unique vessels\n",
      " Initial filtering complete: 8,996,859 rows, 2,933 unique vessels\n",
      " Bounding box filtering complete: 526,788 rows, 227 unique vessels\n",
      " Removed ships with >90% SOG = 0: 41 vessels\n",
      " Removed low-movement vessels (<0.01Â° lat & lon): 22 vessels\n",
      " Final dataframe: 318,864 rows, 164 unique vessels\n"
     ]
    }
   ],
   "source": [
    "df_filtered = ais_filtering.df_filter(df_day, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7d81267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Calculating temporal statistics...\n",
      "\n",
      "âœ… Split complete:\n",
      "   Static:  164 unique vessels with 29 columns\n",
      "   Dynamic: 318,864 AIS messages with 13 columns\n",
      "\n",
      "ðŸ“Š Activity Patterns:\n",
      "   short_stay (<24h):   137 vessels ( 83.5%)\n",
      "   transit (<2h)  :    27 vessels ( 16.5%)\n",
      "\n",
      "â° Time in Area Statistics:\n",
      "   Mean:       6.64 hours\n",
      "   Median:     2.87 hours\n",
      "   Min:        0.29 hours\n",
      "   Max:       24.00 hours\n",
      "\n",
      "âš ï¸  Static conflicts: Name (1), Type of position fixing device (5)\n"
     ]
    }
   ],
   "source": [
    "df_static, df_dynamic = ais_filtering.split_static_dynamic(df_filtered, True, True,\" | \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "516ba27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvati: df_static.parquet, df_dynamic.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    df_static.to_parquet(\"df_static.parquet\", index=False, compression=\"snappy\")\n",
    "    df_dynamic.to_parquet(\"df_dynamic.parquet\", index=False, compression=\"snappy\")\n",
    "    print(\"Salvati: df_static.parquet, df_dynamic.parquet\")\n",
    "except Exception as e:\n",
    "    print(\"Errore nel salvataggio in parquet:\", e)\n",
    "    print(\"Installa pyarrow o fastparquet, ad esempio: pip install pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d7395e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL02456",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
