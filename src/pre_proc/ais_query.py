from pathlib import Path
from typing import Optional, Sequence, Union, List

import duckdb
import pandas as pd


def query_ais_duckdb(
    root_path: Union[str, Path] = "ais-data/parquet",
    dates: Optional[Union[str, Sequence[str]]] = None,
    date_start: Optional[str] = None,
    date_end: Optional[str] = None,
    mmsi: Optional[Union[str, Sequence[str]]] = None,
    segments: Optional[Union[int, Sequence[int]]] = None,
    columns: Optional[Sequence[str]] = None,
    verbose: bool = True,
) -> pd.DataFrame:
    """
    Fast query helper using DuckDB to read AIS data from the partitioned
    parquet dataset generated by `ais_to_parquet`.

    Parameters
    ----------
    root_path : str or Path, optional
        Root directory of the parquet dataset (default: "ais-data/parquet").
    dates : str or list[str], optional
        Date(s) to filter on (e.g. "2025-11-05", or ["2025-11-05", "2025-11-06"]).
        If None, no explicit date list filter is applied.
    date_start : str, optional
        Start date (inclusive) for a date range filter (e.g. "2025-09-01").
        If provided, rows with Date >= date_start are selected.
    date_end : str, optional
        End date (inclusive) for a date range filter (e.g. "2025-10-01").
        If provided, rows with Date <= date_end are selected.
    mmsi : str or list[str], optional
        MMSI or list of MMSIs to filter on. If None, no MMSI filter is applied.
    segments : int or list[int], optional
        Segment ID(s) to filter on. If None, no segment filter is applied.
    columns : list[str], optional
        Subset of columns to select. If None, selects all columns ("*").
    verbose : bool, optional
        If True, prints the generated SQL query.

    Returns
    -------
    pd.DataFrame
        Result of the DuckDB query as a pandas DataFrame.

    Examples
    --------
    # Single day
    >>> df = query_ais_duckdb(dates="2025-11-05")

    # Multiple explicit dates
    >>> df = query_ais_duckdb(dates=["2025-11-05", "2025-11-06"], mmsi="219000123")

    # Date range from 2025-09-01 to 2025-10-01 (inclusive)
    >>> df = query_ais_duckdb(date_start="2025-09-01", date_end="2025-10-01")

    # Date range + subset of columns
    >>> df = query_ais_duckdb(
    ...     date_start="2025-09-01",
    ...     date_end="2025-10-01",
    ...     mmsi=["219000123", "219000456"],
    ...     columns=["MMSI", "Timestamp", "Latitude", "Longitude"]
    ... )
    """
    root_path = Path(root_path)
    if not root_path.exists():
        raise FileNotFoundError(f"No parquet dataset found at: {root_path}")

    # Normalization helpers
    def _to_list(x) -> Optional[List]:
        if x is None:
            return None
        if isinstance(x, (str, int)):
            return [x]
        return list(x)

    def _sql_list_str(values: Sequence[str]) -> str:
        return ", ".join(f"'{v}'" for v in values)

    def _sql_list_int(values: Sequence[int]) -> str:
        return ", ".join(str(v) for v in values)

    dates_list = _to_list(dates)
    mmsi_list = _to_list(mmsi)
    segments_list = _to_list(segments)

    # Columns
    if columns is None:
        col_expr = "*"
    else:
        col_expr = ", ".join(columns)

    parquet_glob = str(root_path / "**" / "*.parquet")

    sql = f"SELECT {col_expr} FROM read_parquet('{parquet_glob}') WHERE 1=1"

    # Explicit date list filter (same behavior as before)
    if dates_list is not None:
        sql += f" AND Date IN ({_sql_list_str([str(d) for d in dates_list])})"

    # New: date range filters (inclusive)
    if date_start is not None and date_end is not None:
        sql += f" AND Date BETWEEN '{date_start}' AND '{date_end}'"
    elif date_start is not None:
        sql += f" AND Date >= '{date_start}'"
    elif date_end is not None:
        sql += f" AND Date <= '{date_end}'"

    # MMSI filter
    if mmsi_list is not None:
        sql += f" AND MMSI IN ({_sql_list_str([str(m) for m in mmsi_list])})"

    # Segment filter
    if segments_list is not None:
        sql += f" AND Segment IN ({_sql_list_int([int(s) for s in segments_list])})"

    if verbose:
        print("[query_ais_duckdb] SQL:\n", sql)

    con = duckdb.connect(database=":memory:")
    df = con.execute(sql).df()
    con.close()

    if verbose:
        row_count = len(df)
        if "MMSI" in df.columns:
            vessel_count = df["MMSI"].nunique()
            vessel_part = f"{vessel_count:,} vessels"
        else:
            vessel_part = "MMSI column not selected"

        if dates_list is not None:
            if len(dates_list) == 1:
                time_msg = f"Date == {dates_list[0]}"
            else:
                joined_dates = ", ".join(str(d) for d in dates_list)
                time_msg = f"Date IN [{joined_dates}]"
        elif date_start is not None and date_end is not None:
            time_msg = f"Date BETWEEN {date_start} and {date_end}"
        elif date_start is not None:
            time_msg = f"Date >= {date_start}"
        elif date_end is not None:
            time_msg = f"Date <= {date_end}"
        else:
            time_msg = "no time filter applied"

        print(f"[query_ais_duckdb] {row_count:,} rows, {vessel_part}; {time_msg}")

    return df